{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcghU7NWULjuU7114/U3FV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auqa5325/AUQA-colab/blob/main/AUQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-uDEQ4a38AH",
        "outputId": "825cf22e-efb1-46e7-e33a-2135fc17c53d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/140.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m133.1/140.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install boto3 -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "AWS_ACCESS_KEY_ID     = userdata.get(\"AWS_ACCESS_KEY_ID\")\n",
        "AWS_SECRET_ACCESS_KEY = userdata.get(\"AWS_SECRET_ACCESS_KEY\")\n",
        "#AWS_SESSION_TOKEN     = userdata.get(\"AWS_SESSION_TOKEN\")  # may be None\n",
        "AWS_REGION = userdata.get(\"AWS_REGION\")\n",
        "\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
        "os.environ[\"AWS_REGION\"] = AWS_REGION\n",
        "\n",
        "print(\"✅ Credentials set. Region:\", AWS_REGION)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE8aVrSE4ZiZ",
        "outputId": "0b14a091-0501-4145-8ada-f40471687b25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Credentials set. Region: ap-south-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3, os\n",
        "\n",
        "REGION = os.environ[\"AWS_REGION\"]\n",
        "session = boto3.Session(region_name=REGION)\n",
        "bedrock         = session.client(\"bedrock\")\n",
        "bedrock_runtime = session.client(\"bedrock-runtime\")\n",
        "print(\"✅ boto3 session initialized in:\", session.region_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaqqWGkX4-QA",
        "outputId": "ae3cd9fe-b29a-4b8c-ffcd-1cb7f8bee865"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ boto3 session initialized in: ap-south-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# output dict structure :\n",
        "* id → unique identifier for this response (good for\n",
        "logging/debugging).\n",
        "\n",
        "* type → \"message\" → tells you this is a message object.\n",
        "\n",
        "* role → \"assistant\" → the speaker role (assistant vs. user).\n",
        "\n",
        "* model → which model gave this reply (claude-3-sonnet-20240229).\n",
        "\n",
        "* content → a list of parts that make up the response.\n",
        "\n",
        "* stop_reason → why the model stopped (e.g., end_turn, max_tokens).\n",
        "\n",
        "* stop_sequence → custom sequence that stopped generation (here it’s None).\n",
        "\n",
        "* usage → token usage info (handy for cost + rate limits)."
      ],
      "metadata": {
        "id": "wbqD05a1_0D-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
        "prompt = \"Hello, can you briefly introduce yourself?\"\n",
        "\n",
        "body = {\n",
        "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
        "    \"max_tokens\": 100,\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}]}\n",
        "    ]\n",
        "}\n",
        "\n",
        "resp = bedrock_runtime.invoke_model(modelId=model_id, body=json.dumps(body))\n",
        "output = json.loads(resp[\"body\"].read())\n",
        "reply = output[\"content\"][0][\"text\"]\n",
        "usage = output.get(\"usage\", {})\n",
        "input_tokens = usage.get(\"input_tokens\")\n",
        "output_tokens = usage.get(\"output_tokens\")\n",
        "print(\"Prompt:\\n\",prompt)\n",
        "print(\"Reply:\\n\", reply)\n",
        "print(\"\\n📊 Usage:\")\n",
        "print(\"  Input tokens :\", input_tokens)\n",
        "print(\"  Output tokens:\", output_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXl1upt35CqY",
        "outputId": "50d6de79-5ff6-49d4-9b4c-a302d108a1fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            " Hello, can you briefly introduce yourself?\n",
            "Reply:\n",
            " Hello! I'm an AI assistant created by Anthropic. I'm knowledgeable about a wide range of topics and can help with all sorts of tasks like research, analysis, writing, coding, and more. I'm driven by a strong sense of ethics and I aim to be caring, honest, and beneficial in my interactions. I'm an artificial intelligence without a physical form, but I have my own personality and opinions. Please let me know if you have any other questions!\n",
            "\n",
            "📊 Usage:\n",
            "  Input tokens : 15\n",
            "  Output tokens: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "model_id = \"mistral.mixtral-8x7b-instruct-v0:1\"\n",
        "prompt = \"explain tcp ip?\"\n",
        "\n",
        "body = {\n",
        "    \"prompt\": prompt,\n",
        "    \"max_tokens\": 100,\n",
        "}\n",
        "\n",
        "resp = bedrock_runtime.invoke_model(modelId=model_id, body=json.dumps(body))\n",
        "output = json.loads(resp[\"body\"].read())\n",
        "print(output[\"outputs\"][0][\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKuzvoVdBegK",
        "outputId": "440ba80e-a429-4cdf-9baa-33ca6e78d447"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "TCP/IP is a suite of protocols that are used to interconnect network devices on the internet. The acronym stands for Transmission Control Protocol/Internet Protocol.\n",
            "\n",
            "TCP is a transport layer protocol that is responsible for providing reliable, ordered delivery of a stream of bytes from a sender to a receiver. It does this by establishing a connection between the two devices and then sending data in small packets, which are reassembled at the receiving end. TCP also provides flow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'outputs': [{'text': '\\n\\nTCP/IP is a suite of protocols that defines the Internet. Originally designed for the UNIX operating system. The TCP/IP protocol suite is a four-layer model that provides end-to-end connectivity specifying how data should be packetized, addressed, transmitted, routed, and received.\\n\\nThe four layers of the TCP/IP model are:\\n\\n1. The Application Layer: This is the topmost layer of the TCP/IP', 'stop_reason': 'length'}]}"
      ],
      "metadata": {
        "id": "zlZJ3onqB_Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l5z2sIp87q1F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}